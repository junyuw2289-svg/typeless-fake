export class AudioRecorder {
  private mediaRecorder: MediaRecorder | null = null;
  private chunks: Blob[] = [];
  private stream: MediaStream | null = null;
  private analyser: AnalyserNode | null = null;
  private audioContext: AudioContext | null = null;

  async start(): Promise<void> {
    this.stream = await navigator.mediaDevices.getUserMedia({
      audio: {
        // ðŸŽ¯ Trick 1: æé«˜é‡‡æ ·çŽ‡åˆ° 48kHz (æ ‡å‡†ä¸“ä¸šéŸ³é¢‘é‡‡æ ·çŽ‡)
        // Whisper å’ŒçŽ°ä»£ ASR æ¨¡åž‹æ”¯æŒæ›´é«˜é‡‡æ ·çŽ‡ï¼Œèƒ½æ•èŽ·æ›´å¤šç»†èŠ‚
        sampleRate: { ideal: 48000 },

        // ðŸŽ¯ Trick 2: å¯ç”¨è‡ªåŠ¨å¢žç›ŠæŽ§åˆ¶ï¼Œä¿æŒéŸ³é‡ä¸€è‡´æ€§
        autoGainControl: true,

        // ðŸŽ¯ Trick 3: å…³é—­æµè§ˆå™¨é™å™ªï¼Œæ”¹ç”¨ AI æ¨¡åž‹çš„é™å™ª
        // æµè§ˆå™¨é™å™ªä¼šæŸå¤±ç»†èŠ‚ï¼Œä¸“ä¸š ASR æ¨¡åž‹è‡ªå¸¦æ›´å¥½çš„å™ªå£°å¤„ç†
        noiseSuppression: false,

        // ðŸŽ¯ Trick 4: ä¿ç•™å›žå£°æ¶ˆé™¤ï¼ˆå¯¹è§†é¢‘é€šè¯åœºæ™¯æœ‰ç”¨ï¼‰
        echoCancellation: true,

        // ðŸŽ¯ Trick 5: å•å£°é“è¶³å¤Ÿï¼Œå‡å°‘æ•°æ®é‡
        channelCount: 1,

        // ðŸŽ¯ Trick 6: è®¾ç½®éŸ³é¢‘ä½æ·±åº¦
        sampleSize: 16,

        // ðŸŽ¯ Trick 7: ä½Žå»¶è¿Ÿè®¾ç½®ï¼Œå‡å°‘ç¼“å†²å»¶è¿Ÿ
        latency: 0,
      },
    });

    // Set up audio analyser for waveform visualization
    this.audioContext = new AudioContext();
    const source = this.audioContext.createMediaStreamSource(this.stream);
    this.analyser = this.audioContext.createAnalyser();
    this.analyser.fftSize = 256;
    source.connect(this.analyser);

    // ðŸŽ¯ Trick 8: ä½¿ç”¨æ›´é«˜çš„éŸ³é¢‘æ¯”ç‰¹çŽ‡ (128kbps)
    // Opus é»˜è®¤å¯èƒ½åªç”¨ 32-64kbpsï¼Œæé«˜åˆ° 128kbps ä¿ç•™æ›´å¤šç»†èŠ‚
    this.mediaRecorder = new MediaRecorder(this.stream, {
      mimeType: 'audio/webm;codecs=opus',
      audioBitsPerSecond: 128000, // 128 kbps
    });

    this.chunks = [];

    this.mediaRecorder.ondataavailable = (e) => {
      if (e.data.size > 0) {
        this.chunks.push(e.data);
      }
    };

    this.mediaRecorder.start(100); // Collect data every 100ms
  }

  stop(): Promise<ArrayBuffer> {
    return new Promise((resolve, reject) => {
      if (!this.mediaRecorder || this.mediaRecorder.state === 'inactive') {
        reject(new Error('No active recording'));
        return;
      }

      this.mediaRecorder.onstop = async () => {
        console.log(`[AudioRecorder] Stopped. Total chunks: ${this.chunks.length}`);
        const blob = new Blob(this.chunks, { type: 'audio/webm' });
        const buffer = await blob.arrayBuffer();
        console.log(`[AudioRecorder] Final buffer size: ${buffer.byteLength} bytes`);

        this.stream?.getTracks().forEach((track) => track.stop());
        this.audioContext?.close();
        this.stream = null;
        this.analyser = null;
        this.audioContext = null;

        resolve(buffer);
      };

      // Force flush any buffered data before stopping
      if (this.mediaRecorder.state === 'recording') {
        this.mediaRecorder.requestData();
      }

      // Small delay to let the final dataavailable event fire,
      // then stop to trigger onstop with all data collected
      setTimeout(() => {
        if (this.mediaRecorder && this.mediaRecorder.state !== 'inactive') {
          this.mediaRecorder.stop();
        }
      }, 150);
    });
  }

  getAnalyser(): AnalyserNode | null {
    return this.analyser;
  }

  isRecording(): boolean {
    return this.mediaRecorder?.state === 'recording';
  }
}
